{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent directory to path: enable import from parent dir\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from environment import GridEnv\n",
    "from actor_critic import A2C\n",
    "from actor_nn import Actor\n",
    "from critic_nn import Critic\n",
    "\n",
    "from IPython.display import Video\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAZE = np.array([\n",
    "    [ 1.,  0.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  0.],\n",
    "    [ 0.,  0.,  1.,  1.],\n",
    "    [ 1.,  0.,  1.,  0.],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = GridEnv(\n",
    "    maze=MAZE.copy(),\n",
    "    is_stochastic=False,\n",
    "    action_transitions={\n",
    "        'w': 1,\n",
    "        's': 1,\n",
    "        'd': 1,\n",
    "        'a': 1,\n",
    "    },\n",
    "    max_timesteps=300,\n",
    "    full_state=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actor_model = Actor(state_dim=16, action_dim=4)\n",
    "critic_model = Critic(state_dim=16)\n",
    "a2c = A2C(\n",
    "    env=env, \n",
    "    actor=actor_model,\n",
    "    critic=critic_model,\n",
    "    n_actns=4,\n",
    "    actor_optmz=torch.optim.Adam(actor_model.parameters(), lr=0.001),\n",
    "    critic_optmz=torch.optim.Adam(critic_model.parameters(), lr=0.001),\n",
    "    hyprprms={\n",
    "        'gamma': 0.995,\n",
    "    },\n",
    "    log_freq=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Loss: 0.9621530771255493, Avg. Reward: -1518.849999999995\n",
      "Episode: 300, Loss: 0.04189596697688103, Avg. Reward: 4.75\n",
      "Episode: 600, Loss: -0.05144035071134567, Avg. Reward: -25.150000000000002\n",
      "Episode: 900, Loss: 0.001211359165608883, Avg. Reward: 4.75\n",
      "Episode: 1200, Loss: 0.0021621210034936666, Avg. Reward: 4.75\n",
      "Episode: 1500, Loss: 4.4564312702277675e-05, Avg. Reward: 4.75\n",
      "Episode: 1800, Loss: 0.007226162124425173, Avg. Reward: 4.75\n",
      "Episode: 2100, Loss: -4.6251986418610613e-07, Avg. Reward: 4.75\n",
      "Episode: 2400, Loss: -0.0023515941575169563, Avg. Reward: 4.75\n",
      "Episode: 2700, Loss: -2.8536567697301507e-05, Avg. Reward: 4.75\n",
      "Episode: 3000, Loss: 1.5892786677795812e-06, Avg. Reward: 4.75\n",
      "Episode: 3300, Loss: 6.70733061269857e-05, Avg. Reward: 4.75\n",
      "Episode: 3600, Loss: 0.006174158770591021, Avg. Reward: 4.75\n",
      "Episode: 3900, Loss: 1.5818210385987186e-06, Avg. Reward: 4.75\n",
      "Episode: 4200, Loss: 2.0394509192556143e-06, Avg. Reward: 4.75\n",
      "Episode: 4500, Loss: 1.74977294875589e-08, Avg. Reward: 4.75\n",
      "Episode: 4800, Loss: -6.743616154381016e-08, Avg. Reward: 4.75\n"
     ]
    }
   ],
   "source": [
    "a2c.run(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dqn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4c81e3cc9a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_one_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_seq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dqn.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mVideo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dqn.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dqn' is not defined"
     ]
    }
   ],
   "source": [
    "_, action_seq = dqn.evaluate_one_episode()\n",
    "dqn.env.animate(action_seq=action_seq, filename='dqn.mp4')\n",
    "Video('dqn.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "total_rewards = [log['reward'] for _, log in dqn.logs.items()]\n",
    "mean_rewards = sum(total_rewards)/len(total_rewards)\n",
    "ax[0][0].plot(range(dqn.episodes), total_rewards)\n",
    "ax[0][0].text(0.5, 0.7, f'Average reward per episode: {round(mean_rewards, 2)}', transform=ax[0][0].transAxes, size='large')\n",
    "ax[0][0].set_title('Total reward per episode')\n",
    "\n",
    "cumulative_rewards = [log['cumulative_reward'] for _, log in dqn.logs.items()]\n",
    "ax[0][1].plot(range(dqn.episodes), cumulative_rewards)\n",
    "ax[0][1].set_title('Cumulative reward per episode')\n",
    "\n",
    "ax[1][0].plot(range(dqn.episodes), [log['epsilon'] for _, log in dqn.logs.items()])\n",
    "ax[1][0].set_title('Epsilon decay per episode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "ax[0].plot(range(dqn.eval_episodes), [log['reward'] for _, log in dqn.eval_logs.items()])\n",
    "ax[0].set_title('Total reward per episode')\n",
    "\n",
    "ax[1].plot(range(dqn.eval_episodes), [log['cumulative_reward'] for _, log in dqn.eval_logs.items()])\n",
    "ax[1].set_title('Cumulative reward per episode')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
