{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent directory to path: enable import from parent dir\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from environment import GridEnv\n",
    "from dqn import DQN\n",
    "from cnn_dueling import DuelingCNN\n",
    "\n",
    "from IPython.display import Video\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAZE = np.array([\n",
    "    [ 1.,  0.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  0.],\n",
    "    [ 0.,  0.,  1.,  1.],\n",
    "    [ 1.,  0.,  1.,  0.],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEvCAYAAADGjk2AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAJ40lEQVR4nO3bT4ich3nH8d9TSVZSxdhQCeM6It6QOBByqGnQJdCDSUHJoX9u8cGnYJ1aHOglpYeSXHTLodCLjE1bMClprZaSJi3GOARDYqdynWBHcRFeTEUCxnETW3HZyM3TgzbFSFt2VtnRzCN/PrCwOzuMfryYr995d97q7gBM9murHgDwqxIyYDwhA8YTMmA8IQPGEzJgvIPLeNHbbrutjx8/voyXHuunb23lx1v+v3G19x/p3HLLLauesVZefuuH+Y26NT/uN1c9Ze389+Z/vdbdx65+fCkhu+OOO3L27NllvPRYT557KQ9fOLLqGWvn9InL2djYWPWMtfKZZ/8sD/76p/LwW19f9ZS18+8P/P0rOz3uFAEYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8XYNWVW9p6qerarvVtWLVfWFGzEMYFEHF3jOVpL7uvtSVR1K8nRVfb27v73kbQAL2TVk3d1JLm3/eGj7q5c5CmAvFrpGVlUHqur5JK8meaK7n1nqKoA9qCsnXAs+uer2JP+Q5I+7+4WrfncqyakkOXr02G9/8S8e2ceZ8x09/Iu8tuVvK1e760jn8OHDq56xdra2thyXHZw8efJcd3/86scXuUb2f7r7J1X1jSQnk7xw1e/OJDmTJB/44If74QtHrn/tTejBD/0sjsm1Tp+4nI2NjVXPWDubm5uOyx4s8lfLY9tnYqmq9yb5ZJIfLHkXwMIWOSO7M8lfV9WBXAnfV7r7q8udBbC4Rf5q+b0k996ALQDXxdVnYDwhA8YTMmA8IQPGEzJgPCEDxhMyYDwhA8YTMmA8IQPGEzJgPCEDxhMyYDwhA8YTMmA8IQPGEzJgPCEDxhMyYDwhA8YTMmA8IQPGEzJgPCEDxhMyYDwhA8YTMmA8IQPGEzJgPCEDxhMyYDwhA8YTMmA8IQPGEzJgPCEDxhMyYDwhA8YTMmA8IQPGEzJgPCEDxhMyYDwhA8YTMmA8IQPGEzJgPCEDxhMyYDwhA8YTMmA8IQPGEzJgPCEDxhMyYDwhA8YTMmA8IQPGEzJgvF1DVlXHq+qpqjpfVS9W1UM3YhjAog4u8Jy3k/xJdz9XVbcmOVdVT3T395e8DWAhu56RdfePuvu57e/fTHI+yV3LHgawqD1dI6uqu5Pcm+SZpawBuA6LvLVMklTV+5I8nuRz3f3GDr8/leRUkhw7diynT1zet5E3g62tdkx2sLW1lc3NzVXPWCsvv/7zHD38izx57qVVTxljoZBV1aFcidhj3X12p+d095kkZ5Lknnvu6Y2NjX0beTPY3NyMY3Itx+Vaf/rsxTz4oZ/l4QtHVj1ljEX+allJHklyvru/tPxJAHuzyDWyTyR5IMl9VfX89tenl7wLYGG7vrXs7qeT1A3YAnBdfLIfGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYT8iA8YQMGE/IgPGEDBhPyIDxhAwYb9eQVdWjVfVqVb1wIwYB7NUiZ2R/leTkkncAXLddQ9bd30zy+g3YAnBdXCMDxju4Xy9UVaeSnEqSY0eP5pWn/3m/Xvqm8MbtH8yT515a9Yy1c9eRzubm5qpnrJXTJ5Ktrc7pE5dXPWXt/H/XuPYtZN19JsmZJLnn7uP9sX/58/166ZvCP/7hY3n4wpFVz1g7p09czsbGxqpnrJ3NzU3HZQ+8tQTGW+TjF19O8q0kH6mqi1X12eXPAljcrm8tu/v+GzEE4Hp5awmMJ2TAeEIGjCdkwHhCBownZMB4QgaMJ2TAeEIGjCdkwHhCBownZMB4QgaMJ2TAeEIGjCdkwHhCBownZMB4QgaMJ2TAeEIGjCdkwHhCBownZMB4QgaMJ2TAeEIGjCdkwHhCBownZMB4QgaMJ2TAeEIGjCdkwHhCBownZMB4QgaMJ2TAeEIGjCdkwHhCBownZMB4QgaMJ2TAeEIGjCdkwHhCBownZMB4QgaMJ2TAeEIGjCdkwHhCBownZMB4QgaMJ2TAeEIGjCdkwHhCBoy3UMiq6mRVvVRVF6rq88seBbAXu4asqg4k+cskn0ry0ST3V9VHlz0MYFGLnJGdSHKhu1/u7p8n+dskv7/cWQCLWyRkdyX5z3f8fHH7MYC1cHCB59QOj/U1T6o6leTU9o9bv/lKXvhVht10/u73jiZ5bdUz1s3JxHHZmeOysw/s9OAiIbuY5Pg7fn5/kh9e/aTuPpPkTJJU1b9198evY+RNyzHZmeOyM8dlbxZ5a/mdJB+uqo2quiXJZ5L803JnASxu1zOy7n67qv4oyb8mOZDk0e5+cenLABa0yFvLdPfXknxtD6975vrm3NQck505LjtzXPaguq+5bg8wiluUgPH2NWRuZbpWVT1aVa9WlY+jvENVHa+qp6rqfFW9WFUPrXrTqlXVe6rq2ar67vYx+cKqN02xb28tt29l+o8kv5srH9n4TpL7u/v7+/IPDFVVv5PkUpK/6e6PrXrPuqiqO5Pc2d3PVdWtSc4l+YN3838vVVVJjnT3pao6lOTpJA9197dXPG3t7ecZmVuZdtDd30zy+qp3rJvu/lF3P7f9/ZtJzuddfsdIX3Fp+8dD218uYi9gP0PmViauS1XdneTeJM+seMrKVdWBqno+yatJnujud/0xWcR+hmyhW5ngnarqfUkeT/K57n5j1XtWrbv/p7t/K1fuoDlRVS5HLGA/Q7bQrUzwS9vXgR5P8lh3n131nnXS3T9J8o0kJ1e7ZIb9DJlbmVjY9oXtR5Kc7+4vrXrPOqiqY1V1+/b3703yySQ/WOmoIfYtZN39dpJf3sp0PslX3MqUVNWXk3wryUeq6mJVfXbVm9bEJ5I8kOS+qnp+++vTqx61YncmeaqqvpcrJwZPdPdXV7xpBJ/sB8bzyX5gPCEDxhMyYDwhA8YTMmA8IQPGEzJgPCEDxvtfLEnW1T+n0noAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = GridEnv(\n",
    "    maze=MAZE.copy(),\n",
    "    is_stochastic=False,\n",
    "    action_transitions={\n",
    "        'w': 1,\n",
    "        's': 1,\n",
    "        'd': 1,\n",
    "        'a': 1,\n",
    "    },\n",
    "    max_timesteps=100,\n",
    "    img_state=True,\n",
    "    greyscale=True,\n",
    "    img_size=(64, 64),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_net = DuelingCNN(\n",
    "    img_dim=1 if env.greyscale else 3,\n",
    "    w=env.img_size[0],\n",
    "    h=env.img_size[1],\n",
    "    input_dim=np.prod(env.img_size),\n",
    "    output_dim=env.n_actions,\n",
    ")\n",
    "\n",
    "policy_net = DuelingCNN(\n",
    "    img_dim=1 if env.greyscale else 3,\n",
    "    w=env.img_size[0],\n",
    "    h=env.img_size[1],\n",
    "    input_dim=np.prod(env.img_size),\n",
    "    output_dim=env.n_actions,\n",
    ")\n",
    "\n",
    "dqn = DQN(\n",
    "    env=env,\n",
    "    log_freq=20,\n",
    "    train_freq=3,\n",
    "    batch_size=10,\n",
    "    w_sync_freq=10,\n",
    "    memory_size=100,\n",
    "    epsilon_start=0.8,\n",
    "    epsilon_decay=0.990,\n",
    "    gamma=0.9,\n",
    "    step_size=0.001,\n",
    "    episodes=300,\n",
    "    target_net=target_net,\n",
    "    policy_net=policy_net,\n",
    "    loss_func=nn.MSELoss(),\n",
    "    optimizer=torch.optim.Adam(policy_net.parameters(), lr=0.01),\n",
    "    load_pretrained=True,\n",
    "    model_path='../models/dqn_with_dueling',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Reward: -107.09999999999998, Loss: 0\n",
      "Episode: 20, Reward: 4.7, Loss: 15.094687461853027\n",
      "Episode: 40, Reward: -52.250000000000014, Loss: 25.25464630126953\n",
      "Episode: 60, Reward: -14.500000000000007, Loss: 6.391191482543945\n",
      "Episode: 80, Reward: 2.2, Loss: 6.328197479248047\n",
      "Episode: 100, Reward: -28.65, Loss: 1.3514368534088135\n",
      "Episode: 120, Reward: 4.75, Loss: 2.0242886543273926\n",
      "Episode: 140, Reward: -25.250000000000004, Loss: 2.435624122619629\n",
      "Episode: 160, Reward: 4.75, Loss: 3.1533396244049072\n",
      "Episode: 180, Reward: -10.200000000000001, Loss: 2.166154384613037\n",
      "Episode: 200, Reward: 4.75, Loss: 0.44999420642852783\n",
      "Episode: 220, Reward: 4.75, Loss: 0.485037624835968\n",
      "Episode: 240, Reward: 4.75, Loss: 0.41135403513908386\n",
      "Episode: 260, Reward: 4.75, Loss: 2.02683162689209\n",
      "Episode: 280, Reward: 4.75, Loss: 1.8485312461853027\n"
     ]
    }
   ],
   "source": [
    "dqn.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DQN' object has no attribute 'policy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e9c2367c3609>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/vinaykudari/Academics-UB/Fall21/CSE546-RL/Assignment/A2/maze-solver/dqn.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, policy)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DQN' object has no attribute 'policy'"
     ]
    }
   ],
   "source": [
    "dqn.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dict = {'w': 'up', 's': 'down', 'a':'left', 'd':'right'}\n",
    "p = np.chararray((dqn.env.w, dqn.env.h), unicode=True)\n",
    "for key, value in dqn.policy.items():\n",
    "    x, y = int(key[0]), int(key[1])\n",
    "    p[x][y] = action_dict[value]\n",
    "    \n",
    "p[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, action_seq = dqn.evaluate_one_episode()\n",
    "dqn.env.animate(action_seq=action_seq, filename='dqn_dueling.mp4')\n",
    "Video('dqn_dueling.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(20, 20))\n",
    "\n",
    "total_rewards = [log['reward'] for _, log in dqn.logs.items()]\n",
    "mean_rewards = sum(total_rewards)/len(total_rewards)\n",
    "ax[0][0].plot(range(dqn.episodes), total_rewards)\n",
    "ax[0][0].text(0.5, 0.7, f'Average reward per episode: {round(mean_rewards, 2)}', transform=ax[0][0].transAxes, size='large')\n",
    "ax[0][0].set_title('Total reward per episode')\n",
    "\n",
    "cumulative_rewards = [log['cumulative_reward'] for _, log in dqn.logs.items()]\n",
    "ax[0][1].plot(range(dqn.episodes), cumulative_rewards)\n",
    "ax[0][1].set_title('Cumulative reward per episode')\n",
    "\n",
    "ax[1][0].plot(range(dqn.episodes), [log['epsilon'] for _, log in dqn.logs.items()])\n",
    "ax[1][0].set_title('Epsilon decay per episode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "ax[0].plot(range(dqn.eval_episodes), [log['reward'] for _, log in dqn.eval_logs.items()])\n",
    "ax[0].set_title('Total reward per episode')\n",
    "\n",
    "ax[1].plot(range(dqn.eval_episodes), [log['cumulative_reward'] for _, log in dqn.eval_logs.items()])\n",
    "ax[1].set_title('Cumulative reward per episode')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
