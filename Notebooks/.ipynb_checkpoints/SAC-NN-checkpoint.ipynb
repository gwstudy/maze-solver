{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff03220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent directory to path: enable import from parent dir\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from environment import GridEnv\n",
    "from sac_disc import SAC\n",
    "from policy_net import PolicyNetwork\n",
    "from q_net import QNetwork\n",
    "\n",
    "from IPython.display import Video\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0fcfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAZE = np.array([\n",
    "    [ 1.,  0.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  0.],\n",
    "    [ 0.,  0.,  1.,  1.],\n",
    "    [ 1.,  0.,  1.,  0.],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b920d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = GridEnv(\n",
    "    maze=MAZE.copy(),\n",
    "    is_stochastic=False,\n",
    "    action_transitions={\n",
    "        'w': 1,\n",
    "        's': 1,\n",
    "        'd': 1,\n",
    "        'a': 1,\n",
    "    },\n",
    "    max_timesteps=300,\n",
    "    full_state=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda072aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sac = SAC(\n",
    "    env=env,\n",
    "    name='maze',\n",
    "    input_dim=env.n_states,\n",
    "    log_freq=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c5128a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting experience...\n",
      "0..50..100..Episode: 150, Reward: -158.94999999999996, Avg. Reward: -254.49500000000006, Policy Loss=45.75\n",
      "Episode: 200, Reward: -103.69999999999997, Avg. Reward: -332.87300000000016, Policy Loss=121.65\n",
      "Episode: 250, Reward: -301.99999999999994, Avg. Reward: -233.06400000000008, Policy Loss=158.97\n",
      "Episode: 300, Reward: -878.2500000000022, Avg. Reward: -363.22100000000034, Policy Loss=181.62\n",
      "Episode: 350, Reward: -169.1999999999994, Avg. Reward: -543.4570000000002, Policy Loss=273.36\n",
      "Episode: 400, Reward: -169.1999999999994, Avg. Reward: -372.5759999999998, Policy Loss=215.58\n",
      "Episode: 450, Reward: -169.1999999999994, Avg. Reward: -169.1999999999994, Policy Loss=142.97\n",
      "Episode: 500, Reward: -169.1999999999994, Avg. Reward: -169.1999999999994, Policy Loss=110.72\n",
      "Episode: 550, Reward: -169.1999999999994, Avg. Reward: -169.1999999999994, Policy Loss=96.35\n",
      "Episode: 600, Reward: -169.1999999999994, Avg. Reward: -169.1999999999994, Policy Loss=89.89\n",
      "Episode: 650, Reward: -169.1999999999994, Avg. Reward: -169.1999999999994, Policy Loss=87.14\n",
      "Episode: 700, Reward: -169.1999999999994, Avg. Reward: -169.1999999999994, Policy Loss=85.87\n",
      "Episode: 750, Reward: -169.1999999999994, Avg. Reward: -169.1999999999994, Policy Loss=85.23\n",
      "Episode: 800, Reward: -169.1999999999994, Avg. Reward: -169.1999999999994, Policy Loss=84.84\n",
      "Episode: 850, Reward: -169.1999999999994, Avg. Reward: -169.1999999999994, Policy Loss=84.57\n",
      "Episode: 900, Reward: -169.1999999999994, Avg. Reward: -169.1999999999994, Policy Loss=84.51\n",
      "Episode: 950, Reward: -169.1999999999994, Avg. Reward: -169.1999999999994, Policy Loss=84.36\n"
     ]
    }
   ],
   "source": [
    "sac.run(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c243176c",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ea10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "total_rewards = [log['reward'] for _, log in sac.logs.items()]\n",
    "mean_rewards = sum(total_rewards)/len(total_rewards)\n",
    "ax[0].plot(range(500), total_rewards)\n",
    "ax[0].text(0.5, 0.7, f'Average reward per episode: {round(mean_rewards, 2)}', transform=ax[0].transAxes, size='large')\n",
    "ax[0].set_title('Total reward per episode')\n",
    "\n",
    "cumulative_rewards = [log['avg_reward'] for _, log in sac.logs.items()]\n",
    "ax[1].plot(range(500), cumulative_rewards)\n",
    "ax[1].set_title('Average reward per episode')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
