{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent directory to path: enable import from parent dir\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from environment import GridEnv\n",
    "from dqn import DQN\n",
    "from cnn import CNN\n",
    "from cnn_dueling import DuelingCNN\n",
    "\n",
    "from IPython.display import Video\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAZE = np.array([\n",
    "    [ 1.,  0.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  0.],\n",
    "    [ 0.,  0.,  1.,  1.],\n",
    "    [ 1.,  0.,  1.,  0.],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = GridEnv(\n",
    "    maze=MAZE.copy(),\n",
    "    is_stochastic=False,\n",
    "    action_transitions={\n",
    "        'w': 1,\n",
    "        's': 1,\n",
    "        'd': 1,\n",
    "        'a': 1,\n",
    "    },\n",
    "    max_timesteps=100,\n",
    "    img_state=True,\n",
    "    greyscale=True,\n",
    "    img_size=(64, 64),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Reward: -683.3500000000006, Loss: 0\n",
      "Episode: 20, Reward: -316.1500000000001, Loss: 140.1908721923828\n",
      "Episode: 40, Reward: -347.4500000000001, Loss: 45.006160736083984\n",
      "Episode: 60, Reward: -44.45, Loss: 12.776573181152344\n",
      "Episode: 80, Reward: -43.699999999999996, Loss: 5.897945404052734\n",
      "Episode: 100, Reward: -168.8999999999998, Loss: 48.08112335205078\n",
      "Episode: 120, Reward: 4.75, Loss: 1.1359227895736694\n",
      "Episode: 140, Reward: -31.29999999999999, Loss: 8.180183410644531\n",
      "Episode: 160, Reward: 4.7, Loss: 0.7865159511566162\n",
      "Episode: 180, Reward: -10.200000000000001, Loss: 0.531674861907959\n",
      "Episode: 200, Reward: -11.200000000000003, Loss: 2.2519707679748535\n",
      "Episode: 220, Reward: 4.75, Loss: 2.2242674827575684\n",
      "Episode: 240, Reward: 4.75, Loss: 0.8308610916137695\n",
      "Episode: 260, Reward: -11.100000000000001, Loss: 3.058582305908203\n",
      "Episode: 280, Reward: 4.75, Loss: 7.804181098937988\n",
      "Episode: 300, Reward: 4.75, Loss: 0.9358103275299072\n",
      "Episode: 320, Reward: 4.75, Loss: 1.466706395149231\n",
      "Episode: 340, Reward: 4.75, Loss: 1.6852229833602905\n",
      "Episode: 360, Reward: 4.75, Loss: 0.3589826226234436\n",
      "Episode: 380, Reward: 4.75, Loss: 0.16802142560482025\n",
      "Episode: 400, Reward: 4.75, Loss: 0.5099459886550903\n",
      "Episode: 420, Reward: 4.75, Loss: 0.3067464828491211\n",
      "Episode: 440, Reward: 4.75, Loss: 0.20412211120128632\n"
     ]
    }
   ],
   "source": [
    "target_net = DuelingCNN(\n",
    "    img_dim=1 if env.greyscale else 3,\n",
    "    w=env.img_size[0],\n",
    "    h=env.img_size[1],\n",
    "    input_dim=np.prod(env.img_size),\n",
    "    output_dim=env.n_actions,\n",
    ")\n",
    "\n",
    "policy_net = DuelingCNN(\n",
    "    img_dim=1 if env.greyscale else 3,\n",
    "    w=env.img_size[0],\n",
    "    h=env.img_size[1],\n",
    "    input_dim=np.prod(env.img_size),\n",
    "    output_dim=env.n_actions,\n",
    ")\n",
    "\n",
    "dqn = DQN(\n",
    "    env=env,\n",
    "    log_freq=20,\n",
    "    train_freq=3,\n",
    "    batch_size=10,\n",
    "    w_sync_freq=10,\n",
    "    memory_size=100,\n",
    "    epsilon_start=0.8,\n",
    "    epsilon_decay=0.990,\n",
    "    gamma=0.9,\n",
    "    step_size=0.001,\n",
    "    episodes=500,\n",
    "    target_net=target_net,\n",
    "    policy_net=policy_net,\n",
    "    loss_func=nn.MSELoss(),\n",
    "    optimizer=torch.optim.Adam(policy_net.parameters(), lr=0.01),\n",
    "    load_pretrained=False,\n",
    "    save_pretrained=False,\n",
    "    model_path='../models/dqn_with_dueling',\n",
    ")\n",
    "\n",
    "dqn.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_net = DuelingCNN(\n",
    "    img_dim=1 if env.greyscale else 3,\n",
    "    w=env.img_size[0],\n",
    "    h=env.img_size[1],\n",
    "    input_dim=np.prod(env.img_size),\n",
    "    output_dim=env.n_actions,\n",
    ")\n",
    "\n",
    "policy_net = DuelingCNN(\n",
    "    img_dim=1 if env.greyscale else 3,\n",
    "    w=env.img_size[0],\n",
    "    h=env.img_size[1],\n",
    "    input_dim=np.prod(env.img_size),\n",
    "    output_dim=env.n_actions,\n",
    ")\n",
    "\n",
    "dqn_dueling = DQN(\n",
    "    env=env,\n",
    "    log_freq=20,\n",
    "    train_freq=3,\n",
    "    batch_size=10,\n",
    "    w_sync_freq=10,\n",
    "    memory_size=100,\n",
    "    epsilon_start=0.8,\n",
    "    epsilon_decay=0.990,\n",
    "    gamma=0.9,\n",
    "    step_size=0.001,\n",
    "    episodes=500,\n",
    "    target_net=target_net,\n",
    "    policy_net=policy_net,\n",
    "    loss_func=nn.MSELoss(),\n",
    "    optimizer=torch.optim.Adam(policy_net.parameters(), lr=0.01),\n",
    "    load_pretrained=False,\n",
    "    save_pretrained=False,\n",
    "    model_path='../models/dqn_with_dueling',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_dueling.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_dueling.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(16, 16))  \n",
    "\n",
    "total_rewards = [log['reward'] for _, log in dqn.logs.items()]\n",
    "mean_rewards = sum(total_rewards)/len(total_rewards)\n",
    "ax[0][0].plot(range(dqn.episodes), total_rewards, label='DQN')\n",
    "ax[0][0].text(0.2, 0.65, f'Average reward per episode for DQN: {round(mean_rewards, 2)}', transform=ax[0][0].transAxes, size='large')\n",
    "ax[0][0].set_title('Total reward per episode')\n",
    "ax[0][0].legend()\n",
    "\n",
    "cumulative_rewards = [log['cumulative_reward'] for _, log in dqn.logs.items()]\n",
    "ax[0][1].plot(range(dqn.episodes), cumulative_rewards, label='DQN')\n",
    "ax[0][1].set_title('Cumulative reward per episode')\n",
    "ax[0][1].legend()\n",
    "\n",
    "ax[1][0].plot(range(dqn.episodes), [log['epsilon'] for _, log in dqn.logs.items()], label='DQN')\n",
    "ax[1][0].set_title('Epsilon decay per episode')\n",
    "ax[1][0].legend()\n",
    "\n",
    "\n",
    "total_rewards_du = [log['reward'] for _, log in dqn_dueling.logs.items()]\n",
    "mean_rewards_du = sum(total_rewards_du)/len(total_rewards_du)\n",
    "ax[0][0].plot(range(dqn_dueling.episodes), total_rewards_du, label='DQN - Dueling')\n",
    "ax[0][0].text(0.2, 0.7, f'Average reward per episode for DQN - Dueling: {round(mean_rewards_du, 2)}', transform=ax[0][0].transAxes, size='large')\n",
    "ax[0][0].set_title('Total reward per episode')\n",
    "ax[0][0].legend()\n",
    "\n",
    "cumulative_rewards_du = [log['cumulative_reward'] for _, log in dqn_dueling.logs.items()]\n",
    "ax[0][1].plot(range(dqn_dueling.episodes), cumulative_rewards_du, label='DQN - Dueling')\n",
    "ax[0][1].set_title('Cumulative reward per episode')\n",
    "ax[0][1].legend()\n",
    "\n",
    "ax[1][0].plot(range(dqn_dueling.episodes), [log['epsilon'] for _, log in dqn_dueling.logs.items()], label='DQN - Dueling')\n",
    "ax[1][0].set_title('Epsilon decay per episode')\n",
    "ax[1][0].legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
